ğŸ¯ EventRadar â€” Full-Stack Event Scraping & Analytics System

A production-ready pipeline that automatically scrapes real-world events (concerts, workshops, conferences, meetups â€” NOT movies) from multiple event platforms, deduplicates the data intelligently, syncs it to Google Sheets, and displays live analytics on a publicly hosted dashboard.


ğŸ“Œ Objective
Build a production-ready, full-stack system that:

Scrapes only EVENTS (not movies or entertainment listings) from event platforms
Stores and deduplicates the data using a 3-layer deduplication engine
Syncs automatically to Google Sheets for easy access
Displays live analytics on a public dashboard URL

This project demonstrates real-world full-stack engineering skills across web scraping, automation, data handling, cloud deployment, and analytics.

ğŸŒ Live Demo
ResourceURLğŸ“Š Live Dashboardhttps://your-app.railway.appğŸ”— Google SheetEventRadar Data Sheetâ¤ï¸ Health Checkhttps://your-app.railway.app/api/health

âœ¨ Features

Multi-platform scraping â€” Eventbrite, Meetup, and Allevents.in
Smart deduplication â€” 3-layer engine (Exact ID â†’ Content Hash â†’ Fuzzy Title Match)
Google Sheets sync â€” All events auto-synced in real time
Live analytics dashboard â€” Charts, filters, and event stats on a public URL
Scheduled scraping â€” Runs automatically every 2 hours
REST API â€” Trigger scrapes, fetch filtered events, view analytics via endpoints
No database needed â€” Google Sheets acts as the data store


ğŸ§  How Deduplication Works
EventRadar uses a 3-layer deduplication engine to ensure no event is stored twice, even across different platforms:
Layer 1 â€” Exact Source ID
Each platform assigns a unique ID to every event. If eventbrite:event_123456 has been seen before, it gets skipped immediately.
Layer 2 â€” Content Hash
A SHA-256 hash is computed from: normalized_title | YYYY-MM-DD | normalized_city. This catches the same real-world event listed on multiple platforms under slightly different names.
Layer 3 â€” Fuzzy Title Match
Uses fuzzy string matching (fuzz.token_sort_ratio). If two events are â‰¥ 85% similar in title AND share the same date AND city, the newer one is flagged as a duplicate.

ğŸ—‚ï¸ Project Structure
event-scraper/
â”œâ”€â”€ main.py              â† FastAPI app + scheduler
â”œâ”€â”€ pipeline.py          â† Orchestrates scrape â†’ dedup â†’ store
â”œâ”€â”€ deduplication.py     â† 3-layer dedup engine
â”œâ”€â”€ sheets.py            â† Google Sheets read/write
â”œâ”€â”€ analytics.py         â† Compute stats from events
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ base.py          â† Base scraper class
â”‚   â”œâ”€â”€ eventbrite.py    â† Eventbrite scraper
â”‚   â”œâ”€â”€ meetup.py        â† Meetup GraphQL scraper
â”‚   â””â”€â”€ allevents.py     â† Allevents.in scraper
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html       â† Dashboard UI
â”œâ”€â”€ credentials.json     â† âš ï¸ Google service account (DO NOT COMMIT)
â”œâ”€â”€ .env                 â† âš ï¸ Your config (DO NOT COMMIT)
â”œâ”€â”€ .env.example         â† Template for environment variables
â”œâ”€â”€ requirements.txt     â† Python dependencies
â””â”€â”€ Dockerfile           â† For deployment

ğŸ“Š Google Sheets Structure
SheetContentseventsAll scraped events (master data)statsAggregated metrics, updated every scrapelogEvery scrape run with timestamps and counts

ğŸ”Œ API Endpoints
MethodEndpointDescriptionGET/Live analytics dashboardGET/api/healthHealth check â€” returns {"status": "healthy"}GET/api/configShows current scraper configGET/api/dashboardRaw analytics JSONGET/api/events?city=Mumbai&limit=10Filtered events by cityPOST/api/scrape/triggerManually trigger a scrape

âš™ï¸ Setup & Installation
Prerequisites

Python 3.11+
A Google Cloud account
Git

Step 1 â€” Clone & Install
bashgit clone https://github.com/YOUR_USERNAME/eventradar.git
cd eventradar

pip install -r requirements.txt
playwright install chromium
Step 2 â€” Google Sheets Setup

Go to Google Cloud Console â†’ Create a new project named EventRadar
Enable the Google Sheets API under APIs & Services â†’ Library
Create a Service Account â†’ Download the JSON key â†’ Save as credentials.json in the project root
Create a new Google Spreadsheet, name it EventRadar Data
Share it with the service account's client_email (from credentials.json) with Editor access
Copy the Spreadsheet ID from the URL

Step 3 â€” Configure Environment
bashcp .env.example .env
Edit .env:
envSPREADSHEET_ID=your_spreadsheet_id_here
GOOGLE_CREDENTIALS_PATH=credentials.json
SCRAPER_CITIES=Mumbai,Delhi,Bangalore,Pune
SCRAPER_CATEGORIES=technology,music,business
SCRAPE_INTERVAL_HOURS=2
PORT=8000
Step 4 â€” Run Locally
bashpython main.py
Visit http://localhost:8000 â€” your dashboard is live!
To manually trigger a scrape:
bashcurl -X POST http://localhost:8000/api/scrape/trigger

ğŸš€ Deployment (Railway â€” Free Public URL)

Push your code to GitHub:

bashgit init
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/YOUR_USERNAME/eventradar.git
git push -u origin main

Go to railway.app â†’ New Project â†’ Deploy from GitHub â†’ Select your repo
Add these environment variables in the Railway dashboard:

SPREADSHEET_ID         = your_sheet_id
GOOGLE_CREDENTIALS_JSON = <paste entire contents of credentials.json>
SCRAPER_CITIES         = Mumbai,Delhi,Bangalore,Pune
SCRAPER_CATEGORIES     = technology,music,business
PORT                   = 8000
Railway will give you a public URL like: https://eventradar-production.railway.app ğŸ‰

Alternative: Render.com â€” same process, gives you https://eventradar.onrender.com


ğŸ”§ Customization
What to changeWhereAdd more citiesSCRAPER_CITIES in .envAdd more categoriesSCRAPER_CATEGORIES in .envChange scrape frequencySCRAPE_INTERVAL_HOURS in .envAdd a new platformCreate scrapers/yourplatform.py extending BaseScraper, implement fetch_events(), register in scrapers/__init__.py

ğŸ”’ Security

Never commit credentials.json or .env to git
Both are listed in .gitignore
On Railway, credentials are passed as an environment variable (GOOGLE_CREDENTIALS_JSON), never as a file
If you accidentally expose your credentials, immediately revoke them from Google Cloud Console â†’ IAM â†’ Service Accounts â†’ Keys


ğŸ“¦ Tech Stack
LayerTechnologyBackendPython, FastAPIScrapingPlaywright, BeautifulSoup, httpxDeduplicationRapidFuzz, hashlibStorage / SyncGoogle Sheets API, gspreadSchedulingAPSchedulerFrontendHTML, CSS, JavaScript (Chart.js)DeploymentRailway / Render (Docker)

ğŸ“„ License
MIT License â€” feel free to use, modify, and distribute.
